(window.webpackJsonp=window.webpackJsonp||[]).push([[654],{1852:function(e,t,o){"use strict";o.r(t);var i=o(19),a=Object(i.a)({},(function(){var e=this,t=e.$createElement,o=e._self._c||t;return o("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[o("h1",{attrs:{id:"computer-vision-optical-flow-mocap-vio-avoidance"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#computer-vision-optical-flow-mocap-vio-avoidance"}},[e._v("#")]),e._v(" Computer Vision (Optical Flow, MoCap, VIO, Avoidance)")]),e._v(" "),o("p",[o("a",{attrs:{href:"https://en.wikipedia.org/wiki/Computer_vision",target:"_blank",rel:"noopener noreferrer"}},[e._v("Computer vision"),o("OutboundLink")],1),e._v(" techniques enable computers to use visual data to make sense of their environment.")]),e._v(" "),o("p",[e._v("PX4 uses computer vision systems (primarily running on "),o("RouterLink",{attrs:{to:"/en/companion_computer/"}},[e._v("Companion Computers")]),e._v(") in order to support the following features:")],1),e._v(" "),o("ul",[o("li",[o("a",{attrs:{href:"#optical-flow"}},[e._v("Optical Flow")]),e._v(" provides 2D velocity estimation (using a downward facing camera and a downward facing distance sensor).")]),e._v(" "),o("li",[o("a",{attrs:{href:"#motion-capture"}},[e._v("Motion Capture")]),e._v(" provides 3D pose estimation using a vision system that is "),o("em",[e._v("external")]),e._v(" to the vehicle.\nIt is primarily used for indoor navigation.")]),e._v(" "),o("li",[o("a",{attrs:{href:"#visual-inertial-odometry-vio"}},[e._v("Visual Inertial Odometry")]),e._v(" provides 3D pose and velocity estimation using an onboard vision system and IMU.\nIt is used for navigation when GNSS position information is absent or unreliable.")]),e._v(" "),o("li",[o("RouterLink",{attrs:{to:"/en/computer_vision/obstacle_avoidance.html"}},[e._v("Obstacle Avoidance")]),e._v(" provides full navigation around obstacles when flying a planned path (currently missions are supported). This uses "),o("a",{attrs:{href:"https://github.com/PX4/PX4-Avoidance",target:"_blank",rel:"noopener noreferrer"}},[e._v("PX4/PX4-Avoidance"),o("OutboundLink")],1),e._v(" running on a companion computer.")],1),e._v(" "),o("li",[o("RouterLink",{attrs:{to:"/en/computer_vision/collision_prevention.html"}},[e._v("Collision Prevention")]),e._v(" is used to stop vehicles before they can crash into an obstacle (primarily when flying in manual modes).")],1)]),e._v(" "),o("div",{staticClass:"custom-block tip"},[o("p",{staticClass:"custom-block-title"},[e._v("TIP")]),e._v(" "),o("p",[e._v("The "),o("RouterLink",{attrs:{to:"/en/complete_vehicles_mc/px4_vision_kit.html"}},[e._v("PX4 Vision Autonomy Development Kit")]),e._v(" (Holybro) is a robust and inexpensive kit for developers working with computer vision on PX4.\nIt comes with no pre-installed software, but does include an example implementation of obstacle avoidance to demonstrate the capabilities of the platform.")],1)]),e._v(" "),o("h2",{attrs:{id:"motion-capture"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#motion-capture"}},[e._v("#")]),e._v(" Motion Capture")]),e._v(" "),o("p",[e._v("Motion Capture (MoCap) is a technique for estimating the 3D "),o("em",[e._v("pose")]),e._v(" (position and orientation) of a vehicle using a positioning mechanism that is "),o("em",[e._v("external")]),e._v(" to the vehicle.\nMoCap systems most commonly detect motion using infrared cameras, but other types of cameras, Lidar, or Ultra Wideband (UWB) may also be used.")]),e._v(" "),o("div",{staticClass:"custom-block note"},[o("p",{staticClass:"custom-block-title"},[e._v("Note")]),e._v(" "),o("p",[e._v("MoCap is commonly used to navigate a vehicle in situations where GPS is absent (e.g. indoors), and provides position relative to a "),o("em",[e._v("local")]),e._v(" coordinate system.")])]),e._v(" "),o("p",[e._v("For information about MoCap see:")]),e._v(" "),o("ul",[o("li",[o("RouterLink",{attrs:{to:"/en/ros/external_position_estimation.html"}},[e._v("External Position Estimation")])],1),e._v(" "),o("li",[o("RouterLink",{attrs:{to:"/en/tutorials/motion-capture.html"}},[e._v("Flying with Motion Capture (VICON, NOKOV, Optitrack)")])],1),e._v(" "),o("li",[o("RouterLink",{attrs:{to:"/en/advanced_config/tuning_the_ecl_ekf.html#external-vision-system"}},[e._v("EKF > External Vision System")])],1)]),e._v(" "),o("h2",{attrs:{id:"visual-inertial-odometry-vio"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#visual-inertial-odometry-vio"}},[e._v("#")]),e._v(" Visual Inertial Odometry (VIO)")]),e._v(" "),o("p",[e._v("Visual Inertial Odometry (VIO) is used for estimating the 3D "),o("em",[e._v("pose")]),e._v(" (position and orientation) and "),o("em",[e._v("velocity")]),e._v(" of a moving vehicle relative to a "),o("em",[e._v("local")]),e._v(" starting position.\nIt is commonly used to navigate a vehicle in situations where GPS is absent (e.g. indoors) or unreliable (e.g. when flying under a bridge).")]),e._v(" "),o("p",[e._v("VIO uses "),o("a",{attrs:{href:"https://en.wikipedia.org/wiki/Visual_odometry",target:"_blank",rel:"noopener noreferrer"}},[e._v("Visual Odometry"),o("OutboundLink")],1),e._v(" to estimate vehicle "),o("em",[e._v("pose")]),e._v(" from visual information, combined with inertial measurements from an IMU (to correct for errors associated with rapid vehicle movement resulting in poor image capture).")]),e._v(" "),o("div",{staticClass:"custom-block note"},[o("p",{staticClass:"custom-block-title"},[e._v("Note")]),e._v(" "),o("p",[e._v("One difference between VIO and "),o("a",{attrs:{href:"#motion-capture"}},[e._v("MoCap")]),e._v(" is that VIO cameras/IMU are vehicle-based, and additionally provide velocity information.")])]),e._v(" "),o("p",[e._v("For information about configuring VIO on PX4 see:")]),e._v(" "),o("ul",[o("li",[o("RouterLink",{attrs:{to:"/en/advanced_config/tuning_the_ecl_ekf.html#external-vision-system"}},[e._v("EKF > External Vision System")])],1),e._v(" "),o("li",[o("RouterLink",{attrs:{to:"/en/peripherals/camera_t265_vio.html"}},[e._v("T265 Setup guide")])],1)]),e._v(" "),o("h2",{attrs:{id:"optical-flow"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#optical-flow"}},[e._v("#")]),e._v(" Optical Flow")]),e._v(" "),o("p",[o("RouterLink",{attrs:{to:"/en/sensor/optical_flow.html"}},[e._v("Optical Flow")]),e._v(" provides 2D velocity estimation (using a downward facing camera and a downward facing distance sensor).")],1),e._v(" "),o("p",[e._v("For information about optical flow see:")]),e._v(" "),o("ul",[o("li",[o("RouterLink",{attrs:{to:"/en/sensor/optical_flow.html"}},[e._v("Optical Flow")])],1),e._v(" "),o("li",[o("RouterLink",{attrs:{to:"/en/advanced_config/tuning_the_ecl_ekf.html#optical-flow"}},[e._v("EKF > Optical Flow")])],1)]),e._v(" "),o("h2",{attrs:{id:"comparisons"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#comparisons"}},[e._v("#")]),e._v(" Comparisons")]),e._v(" "),o("h3",{attrs:{id:"optical-flow-vs-vio-for-local-position-estimation"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#optical-flow-vs-vio-for-local-position-estimation"}},[e._v("#")]),e._v(" Optical Flow vs VIO for Local Position Estimation")]),e._v(" "),o("p",[e._v("Both these techniques use cameras and measure differences between frames.\nOptical flow uses a downward facing camera, while VIO uses a stereo camera or a 45 degree tracking camera.\nAssuming both are well calibrated, which is better for local position estimation?")]),e._v(" "),o("p",[e._v("The consensus "),o("a",{attrs:{href:"https://discuss.px4.io/t/vio-vs-optical-flow/34680",target:"_blank",rel:"noopener noreferrer"}},[e._v("appears to be"),o("OutboundLink")],1),e._v(":")]),e._v(" "),o("p",[e._v("Optical flow:")]),e._v(" "),o("ul",[o("li",[e._v("Downward facing optical flow gives you a planar velocity thats corrected for angular velocity with the gyro.")]),e._v(" "),o("li",[e._v("Requires an accurate distance to the ground and assumes a planar surface.\nGiven those conditions it can be just as accurate/reliable as VIO (such as indoor flight)")]),e._v(" "),o("li",[e._v("Is more robust than VIO as it has fewer states.")]),e._v(" "),o("li",[e._v("Is significantly cheaper and easier to set up as it only requires a flow sensor, a rangefinder, and setting up a few parameters (which can be connected to the flight controller).")])]),e._v(" "),o("p",[e._v("VIO:")]),e._v(" "),o("ul",[o("li",[e._v("Is more expensive to purchase and harder to set up.\nIt requires a separate companion computer, calibration, software, configuration and so on.")]),e._v(" "),o("li",[e._v("Will be less effective if there are no point features to track (in practice the real world generally has point features).")]),e._v(" "),o("li",[e._v("Is more flexible, allowing additional features such as obstacle avoidance and mapping.")])]),e._v(" "),o("p",[e._v("A combination (fusing both) is probably the most reliable, though not necessary in most real-world scenarios.\nNormally you will select the system that suits your operating environment, required features, and cost constraints:")]),e._v(" "),o("ul",[o("li",[e._v("Use VIO if you plan on flying outdoors without GPS (or outdoors and indoors), or if you need to support obstacle avoidance and other computer vision features.")]),e._v(" "),o("li",[e._v("Use Optical Flow if you plan on only flying indoors (without GPS) and cost is an important consideration.")])]),e._v(" "),o("h2",{attrs:{id:"external-resources"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#external-resources"}},[e._v("#")]),e._v(" External Resources")]),e._v(" "),o("ul",[o("li",[o("a",{attrs:{href:"https://github.com/robin-shaun/XTDrone/blob/master/README.en.md",target:"_blank",rel:"noopener noreferrer"}},[e._v("XTDrone"),o("OutboundLink")],1),e._v(" - ROS + PX4 simulation environment for computer vision.\nThe "),o("a",{attrs:{href:"https://www.yuque.com/xtdrone/manual_en",target:"_blank",rel:"noopener noreferrer"}},[e._v("XTDrone Manual"),o("OutboundLink")],1),e._v(" has everything you need to get started!")])])])}),[],!1,null,null,null);t.default=a.exports}}]);