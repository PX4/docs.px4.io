import{_ as i}from"./chunks/ekf2_ev_delay_tuning.Bgxz8N1S.js";import{_ as s}from"./chunks/ref_frames.C52lwBbQ.js";import{_ as n,c as a,m as e,a as t,ab as o,o as r}from"./chunks/framework.CUflZczI.js";const R=JSON.parse('{"title":"利用视觉或运动捕捉系统进行位置估计","description":"","frontmatter":{},"headers":[],"relativePath":"zh/ros/external_position_estimation.md","filePath":"zh/ros/external_position_estimation.md"}'),l={name:"zh/ros/external_position_estimation.md"},h=o('<h1 id="利用视觉或运动捕捉系统进行位置估计" tabindex="-1">利用视觉或运动捕捉系统进行位置估计 <a class="header-anchor" href="#利用视觉或运动捕捉系统进行位置估计" aria-label="Permalink to &quot;利用视觉或运动捕捉系统进行位置估计&quot;">​</a></h1><p>可视惯性测距（VIO）和运动捕捉（MOCAP）系统允许载具在全局位置源不可用或不可靠时（例如在室内，或在桥下飞行时）导航。 等等……</p><p>VIO 和 MOCAP 都从“视觉”信息中确定飞机的 <em>pose</em> （位置和姿态）。 它们之间的主要区别是框架透视图：</p><ul><li>VIO 使用 *板载传感器 * 从车辆的角度获取姿势数据（见 <a href="https://en.wikipedia.org/wiki/Visual_odometry#Egomotion" target="_blank" rel="noreferrer">egomotion</a>）。</li><li>MoCap 使用 <em>离板摄像机</em> 系统在 3D 空间中获取飞机姿态数据（即它是一个外部系统，告诉飞机其姿态）。</li></ul><p>任何类型系统的 Pose 数据都可用于更新基于 PX4 自动驾驶仪的局部位置估计（相对于本地源），也可以选择融合到飞机姿态估计中。 Additionally, if the external pose system also provides linear velocity measurements, it can be used to improve the state estimate (fusion of linear velocity measurements is only supported by the EKF2).</p><p>本主题介绍如何配置基于 px4 的系统，以便从 MoCap/VIO 系统（通过 ROS 或其他 MAVLink 系统）获取数据，更具体地说明如何设置 MoCap 系统，如 VICON 和 Optitrack，以及基于视觉的估计系统（如 <a href="https://github.com/ethz-asl/rovio" target="_blank" rel="noreferrer">ROVIO</a>、<a href="https://github.com/uzh-rpg/rpg_svo" target="_blank" rel="noreferrer">SVO</a> 和 <a href="https://github.com/ethz-asl/ethzasl_ptam" target="_blank" rel="noreferrer">PTAM</a>）。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>The instructions differ depending on whether you are using the EKF2 or LPE estimator.</p></div><h2 id="px4-mavlink-集成" tabindex="-1">PX4 MAVLink 集成 <a class="header-anchor" href="#px4-mavlink-集成" aria-label="Permalink to &quot;PX4 MAVLink 集成&quot;">​</a></h2><p>PX4 uses the following MAVLink messages for getting external position information, and maps them to <a href="./../middleware/uorb.html">uORB topics</a>:</p><table><thead><tr><th>MAVLink</th><th>uORB</th></tr></thead><tbody><tr><td><a href="https://mavlink.io/en/messages/common.html#VISION_POSITION_ESTIMATE" target="_blank" rel="noreferrer">VISION_POSITION_ESTIMATE</a></td><td><code>vehicle_visual_odometry</code></td></tr><tr><td><a href="https://mavlink.io/en/messages/common.html#ODOMETRY" target="_blank" rel="noreferrer">ODOMETRY</a> (<code>frame_id =</code> <a href="https://mavlink.io/en/messages/common.html#MAV_FRAME_VISION_NED" target="_blank" rel="noreferrer">MAV_FRAME_VISION_NED</a>)</td><td><code>vehicle_visual_odometry</code></td></tr><tr><td><a href="https://mavlink.io/en/messages/common.html#ATT_POS_MOCAP" target="_blank" rel="noreferrer">ATT_POS_MOCAP</a></td><td><code>vehicle_mocap_odometry</code></td></tr><tr><td><a href="https://mavlink.io/en/messages/common.html#ODOMETRY" target="_blank" rel="noreferrer">ODOMETRY</a> (<code>frame_id =</code> <a href="https://mavlink.io/en/messages/common.html#MAV_FRAME_MOCAP_NED" target="_blank" rel="noreferrer">MAV_FRAME_MOCAP_NED</a>)</td><td><code>vehicle_mocap_odometry</code></td></tr></tbody></table><p>EKF2 only subscribes to <code>vehicle_visual_odometry</code> topics and can hence only process the first two messages (a MoCap system must generate these messages to work with EKF2). The odometry message is the only message that can send also linear velocities to PX4. The LPE estimator subscribes to both topics, and can hence process all the above messages.</p><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>EKF2 is the default estimator used by PX4. It is better tested and supported than LPE, and should be used by preference.</p></div><p>The messages should be streamed at between 30Hz (if containing covariances) and 50 Hz. If the message rate is too low, EKF2 will not fuse the external vision messages.</p><p>The following MAVLink &quot;vision&quot; messages are not currently supported by PX4: <a href="https://mavlink.io/en/messages/common.html#GLOBAL_VISION_POSITION_ESTIMATE" target="_blank" rel="noreferrer">GLOBAL_VISION_POSITION_ESTIMATE</a>, <a href="https://mavlink.io/en/messages/common.html#VISION_SPEED_ESTIMATE" target="_blank" rel="noreferrer">VISION_SPEED_ESTIMATE</a>, <a href="https://mavlink.io/en/messages/common.html#VICON_POSITION_ESTIMATE" target="_blank" rel="noreferrer">VICON_POSITION_ESTIMATE</a></p><h2 id="参考机架" tabindex="-1">参考机架 <a class="header-anchor" href="#参考机架" aria-label="Permalink to &quot;参考机架&quot;">​</a></h2><p>例如，如果使用 optitrack 框架，则本地框架在水平面上具有 $$x$$ 和 $$z$$（<em>x</em> 正面和 <em>z</em> 右），而 <em>y</em> 轴是垂直的，指向上方。 通过如下转换我们可以转换optrack坐标系到NED系中。 The heading of the reference frame of the PX4 estimator and the one of the external pose estimate will not match in most cases. Therefore the reference frame of the external pose estimate is named differently, it is called <a href="https://mavlink.io/en/messages/common.html#MAV_FRAME_LOCAL_FRD" target="_blank" rel="noreferrer">MAV_FRAME_LOCAL_FRD</a>.</p><p>Depending on the source of your reference frame, you will need to apply a custom transformation to the pose estimate before sending the MAVLink Vision/MoCap message. This is necessary to change the orientation of the parent and child frame of the pose estimate, such that it fits the PX4 convention. Have a look at the MAVROS <a href="https://github.com/mavlink/mavros/blob/master/mavros_extras/src/plugins/odom.cpp" target="_blank" rel="noreferrer"><em>odom</em> plugin</a> for the necessary transformations.</p><p>在方向方面，保持标量部分 <em>w</em> 四元数，并以相同的方式交换矢量部分 <em>x</em>、<em>y</em> 和 <em>z</em>。 您可以将此技巧应用于每个系统-如果您需要获取 NED 帧，请相应地查看您的 MoCap 输出和交换轴。</p>',18),d={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},c={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.025ex"},xmlns:"http://www.w3.org/2000/svg",width:"1.294ex",height:"1.025ex",role:"img",focusable:"false",viewBox:"0 -442 572 453","aria-hidden":"true"},m=o('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(572,0)"></g></g></g>',1),p=[m],f=e("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("mi",null,"x"),e("mrow",{"data-mjx-texclass":"ORD"})])],-1),_={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},u={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.025ex"},xmlns:"http://www.w3.org/2000/svg",width:"1.052ex",height:"1.025ex",role:"img",focusable:"false",viewBox:"0 -442 465 453","aria-hidden":"true"},g=o('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(465,0)"></g></g></g>',1),b=[g],y=e("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("mi",null,"z"),e("mrow",{"data-mjx-texclass":"ORD"})])],-1),v=e("em",null,"x",-1),k=e("em",null,"z",-1),w=e("em",null,"y",-1),E=o(`<p>If <code>x_{mav}</code>, <code>y_{mav}</code> and <code>z_{mav}</code> are the coordinates that are sent through MAVLink as position feedback, then we obtain:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span>x_{mav} = x_{mocap}</span></span>
<span class="line"><span>y_{mav} = z_{mocap}</span></span>
<span class="line"><span>z_{mav} = - y_{mocap}</span></span></code></pre></div><p>Regarding the orientation, keep the scalar part <em>w</em> of the quaternion the same and swap the vector part <em>x</em>, <em>y</em> and <em>z</em> in the same way. You can apply this trick with every system - if you need to obtain a NED frame, look at your MoCap output and swap axis accordingly.</p><h2 id="ekf2-调参-配置" tabindex="-1">EKF2 调参/配置 <a class="header-anchor" href="#ekf2-调参-配置" aria-label="Permalink to &quot;EKF2 调参/配置&quot;">​</a></h2><p>Note: this is a quick overview. For more detailed information, check the <a href="./../advanced_config/tuning_the_ecl_ekf.html">EKF2 tuning guide</a></p><p>The following parameters must be set to use external position information with EKF2 (these can be set in <em>QGroundControl</em> &gt; <strong>Vehicle Setup &gt; Parameters &gt; EKF2</strong>).</p><table><thead><tr><th>参数</th><th>外部位置估计的设置</th></tr></thead><tbody><tr><td><a href="./../advanced_config/parameter_reference.html#EKF2_EV_CTRL">EKF2_EV_CTRL</a></td><td>Set <em>horizontal position fusion</em>, <em>vertical vision fusion</em>, <em>velocity fusion</em>, and <em>yaw fusion</em>, according to your desired fusion model.</td></tr><tr><td><a href="./../advanced_config/parameter_reference.html#EKF2_HGT_REF">EKF2_HGT_REF</a></td><td>Set to <em>Vision</em> to use the vision as the reference source for altitude estimation.</td></tr><tr><td><a href="./../advanced_config/parameter_reference.html#EKF2_EV_DELAY">EKF2_EV_DELAY</a></td><td>设置为测量的时间戳和 &quot;实际&quot; 捕获时间之间的差异。 有关详细信息，请参阅 <a href="#tuning-EKF2_EV_DELAY">below</a>。</td></tr><tr><td><a href="./../advanced_config/parameter_reference.html#EKF2_EV_POS_X">EKF2_EV_POS_X</a>, <a href="./../advanced_config/parameter_reference.html#EKF2_EV_POS_Y">EKF2_EV_POS_Y</a>, <a href="./../advanced_config/parameter_reference.html#EKF2_EV_POS_Z">EKF2_EV_POS_Z</a></td><td>设置视觉传感器（或 MoCap 标记）相对于机器人的车身框架的位置。</td></tr></tbody></table><p>You can also disable GNSS, baro and range finder fusion using <a href="./../advanced_config/parameter_reference.html#EKF2_GPS_CTRL">EKF2_GPS_CTRL</a>, <a href="./../advanced_config/parameter_reference.html#EKF2_BARO_CTRL">EKF2_BARO_CTRL</a> and <a href="./../advanced_config/parameter_reference.html#EKF2_RNG_CTRL">EKF2_RNG_CTRL</a>, respectively.</p><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>Reboot the flight controller in order for parameter changes to take effect.</p></div><p><a id="tuning-EKF2_EV_DELAY"></a></p><h4 id="调参-ekf2-ev-delay" tabindex="-1">调参 EKF2_EV_DELAY <a class="header-anchor" href="#调参-ekf2-ev-delay" aria-label="Permalink to &quot;调参 EKF2_EV_DELAY&quot;">​</a></h4><p><a href="./../advanced_config/parameter_reference.html#EKF2_EV_DELAY">EKF2_EV_DELAY</a> is the <em>Vision Position Estimator delay relative to IMU measurements</em>.</p><p>该值可以通过不同的参数一起调整，在动态变化中来保证最低 EKF 。</p><p>Technically this can be set to 0 if there is correct timestamping (not just arrival time) and timesync (e.g NTP) between MoCap and (for example) ROS computers. In reality, this needs some empirical tuning since delays in the entire MoCap-&gt;PX4 chain are very setup-specific. It is rare that a system is setup with an entirely synchronised chain!</p><p>A rough estimate of the delay can be obtained from logs by checking the offset between IMU rates and the EV rates. To enable logging of EV rates set bit 7 (Computer Vision and Avoidance) of <a href="./../advanced_config/parameter_reference.html#SDLOG_PROFILE">SDLOG_PROFILE</a>.</p><p><img src="`+i+'" alt="ekf2_ev_delay log"></p><div class="info custom-block"><p class="custom-block-title">A plot of external data vs. onboard estimate (as above) can be generated using <a href="./../log/flight_log_analysis.html#flightplot">FlightPlot</a> or similar flight analysis tools. At time of writing (July 2021) neither <a href="./../log/flight_log_analysis.html#flight-review-online-tool">Flight Review</a> nor <a href="./../log/flight_log_analysis.html#mavgcl">MAVGCL</a> support this functionality.</p></div><p>The value can further be tuned by varying the parameter to find the value that yields the lowest EKF innovations during dynamic maneuvers.</p><h2 id="lpe-调参-配置" tabindex="-1">LPE 调参/配置 <a class="header-anchor" href="#lpe-调参-配置" aria-label="Permalink to &quot;LPE 调参/配置&quot;">​</a></h2><p>You will first need to <a href="./../advanced/switching_state_estimators.html">switch to the LPE estimator</a> by setting the following parameters: <a href="./../advanced_config/parameter_reference.html#LPE_EN">LPE_EN</a> (1), <a href="./../advanced_config/parameter_reference.html#EKF2_EN">EKF2_EN</a> (0), <a href="./../advanced_config/parameter_reference.html#ATT_EN">ATT_EN</a> (0).</p><div class="info custom-block"><p class="custom-block-title">If targeting <code>px4_fmu-v2</code> hardware you will also need to use a firmware version that includes the LPE module (firmware for other FMU-series hardware includes both LPE and EKF). The LPE version can be found in the zip file for each PX4 release or it can be built from source using the build command <code>make px4_fmu-v2_lpe</code>. See <a href="./../dev_setup/building_px4.html">Building the Code</a> for more details.</p></div><h3 id="启用外部位置输入" tabindex="-1">启用外部位置输入 <a class="header-anchor" href="#启用外部位置输入" aria-label="Permalink to &quot;启用外部位置输入&quot;">​</a></h3><p>The following parameters must be set to use external position information with LPE (these can be set in <em>QGroundControl</em> &gt; <strong>Vehicle Setup &gt; Parameters &gt; Local Position Estimator</strong>).</p><table><thead><tr><th>参数</th><th>外部位置估计的设置</th></tr></thead><tbody><tr><td><a href="./../advanced_config/parameter_reference.html#LPE_FUSION">LPE_FUSION</a></td><td>如果选中了 *fuse 视觉位置 *（默认情况下启用），则启用视觉集成。</td></tr><tr><td><a href="./../advanced_config/parameter_reference.html#ATT_EXT_HDG_M">ATT_EXT_HDG_M</a></td><td>设置为1或 2，以启用外部标题集成。 Set to 1 or 2 to enable external heading integration. Setting it to 1 will cause vision to be used, while 2 enables MoCap heading use.</td></tr></tbody></table><h3 id="禁用气压计融合" tabindex="-1">禁用气压计融合 <a class="header-anchor" href="#禁用气压计融合" aria-label="Permalink to &quot;禁用气压计融合&quot;">​</a></h3><p>MAVROS 具有插件，可使用以下管道从 VIO 或 MOCAP 系统中继可视化估计：</p><p>您可以将上述任何管道与 LPE 一起使用。</p><h3 id="滤波噪声参数调参" tabindex="-1">滤波噪声参数调参 <a class="header-anchor" href="#滤波噪声参数调参" aria-label="Permalink to &quot;滤波噪声参数调参&quot;">​</a></h3><p>如果您使用的是 EKF2，则仅支持 &quot;视觉&quot; 管道。 If you&#39;re working with EKF2, only the &quot;vision&quot; pipelines are supported. To use MoCap data with EKF2 you will have to <a href="http://wiki.ros.org/roslaunch/XML/remap" target="_blank" rel="noreferrer">remap</a> the pose topic that you get from MoCap: You may need to set them lower than the allowed minimum and force-save.</p><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>If performance is still poor, try increasing the <a href="./../advanced_config/parameter_reference.html#LPE_PN_V">LPE_PN_V</a> parameter. This will cause the estimator to trust measurements more during velocity estimation.</p></div><h2 id="enabling-auto-modes-with-a-local-position" tabindex="-1">Enabling Auto Modes with a Local Position <a class="header-anchor" href="#enabling-auto-modes-with-a-local-position" aria-label="Permalink to &quot;Enabling Auto Modes with a Local Position&quot;">​</a></h2><p>All PX4 automatic flight modes (such as <a href="./../flight_modes_mc/mission.html">Mission</a>, <a href="./../flight_modes_mc/return.html">Return</a>, <a href="./../flight_modes_mc/land.html">Land</a>, <a href="./../flight_modes_mc/land.html">Hold</a>, <a href="./../flight_modes_mc/orbit.html">Orbit</a>)) require a <em>global</em> position estimate, which would normally come from a GPS/GNSS system.</p><p>Systems that only have a <em>local</em> position estimate (from MOCAP, VIO, or similar) can use the <a href="https://mavlink.io/en/messages/common.html#SET_GPS_GLOBAL_ORIGIN" target="_blank" rel="noreferrer">SET_GPS_GLOBAL_ORIGIN</a> MAVLink message to set the origin of the EKF to a particular global location. EKF will then provide a global position estimate based on origin and local frame position.</p><p>This can then be used when planning and executing indoor missions, or to set a local return point, and so on.</p><h2 id="使用-ros" tabindex="-1">使用 ROS <a class="header-anchor" href="#使用-ros" aria-label="Permalink to &quot;使用 ROS&quot;">​</a></h2><p>ROS is not <em>required</em> for supplying external pose information, but is highly recommended as it already comes with good integrations with VIO and MoCap systems. PX4 must already have been set up as above.</p><h3 id="将数据输入-ros" tabindex="-1">将数据输入 ROS <a class="header-anchor" href="#将数据输入-ros" aria-label="Permalink to &quot;将数据输入 ROS&quot;">​</a></h3><p>VIO and MoCap systems have different ways of obtaining pose data, and have their own setup and topics.</p><p>The setup for specific systems is covered <a href="#setup_specific_systems">below</a>. When using external heading estimation, magnetic North is ignored and faked with a vector corresponding to world <em>x</em> axis (which can be placed freely during Vision/MoCap calibration). Yaw angle is therefore given with respect to local <em>x</em>.</p><p><a id="relaying_pose_data_to_px4"></a></p><h3 id="将数据回传给-px4" tabindex="-1">将数据回传给 PX4 <a class="header-anchor" href="#将数据回传给-px4" aria-label="Permalink to &quot;将数据回传给 PX4&quot;">​</a></h3><p>MAVROS has plugins to relay a visual estimation from a VIO or MoCap system using the following pipelines:</p><table><thead><tr><th>ROS</th><th>MAVLink</th><th>uORB</th></tr></thead><tbody><tr><td>/mavros/vision_pose/pose</td><td><a href="https://mavlink.io/en/messages/common.html#VISION_POSITION_ESTIMATE" target="_blank" rel="noreferrer">VISION_POSITION_ESTIMATE</a></td><td><code>vehicle_visual_odometry</code></td></tr><tr><td>/mavros/odometry/odom</td><td><a href="https://mavlink.io/en/messages/common.html#ODOMETRY" target="_blank" rel="noreferrer">ODOMETRY</a> (<code>frame_id =</code> <a href="https://mavlink.io/en/messages/common.html#MAV_FRAME_VISION_NED" target="_blank" rel="noreferrer">MAV_FRAME_VISION_NED</a>)</td><td><code>vehicle_visual_odometry</code></td></tr><tr><td>/mavros/mocap/pose</td><td><a href="https://mavlink.io/en/messages/common.html#ATT_POS_MOCAP" target="_blank" rel="noreferrer">ATT_POS_MOCAP</a></td><td><code>vehicle_mocap_odometry</code></td></tr><tr><td>/mavros/odometry/odom</td><td><a href="https://mavlink.io/en/messages/common.html#ODOMETRY" target="_blank" rel="noreferrer">ODOMETRY</a> (<code>frame_id =</code> <a href="https://mavlink.io/en/messages/common.html#MAV_FRAME_VISION_NED" target="_blank" rel="noreferrer">MAV_FRAME_VISION_NED</a>)</td><td><code>vehicle_mocap_odometry</code></td></tr></tbody></table><p>You can use any of the above pipelines with LPE.</p><p>If you&#39;re working with EKF2, only the &quot;vision&quot; pipelines are supported. To use MoCap data with EKF2 you will have to <a href="http://wiki.ros.org/roslaunch/XML/remap" target="_blank" rel="noreferrer">remap</a> the pose topic that you get from MoCap:</p><ul><li>MoCap ROS topics of type <code>geometry_msgs/PoseStamped</code> or <code>geometry_msgs/PoseWithCovarianceStamped</code> must be remapped to <code>/mavros/vision_pose/pose</code>. The <code>geometry_msgs/PoseStamped</code> topic is most common as MoCap doesn&#39;t usually have associated covariances to the data. <code>geometry_msgs/PoseStamped</code> 主题是最常见的，因为 mocap 通常没有与数据相关的协方差。</li><li>If you get data through a <code>nav_msgs/Odometry</code> ROS message then you will need to remap it to <code>/mavros/odometry/odom</code>.</li><li>The odometry frames <code>frame_id = odom</code>, <code>child_frame_id = base_link</code> can be changed by updating the file in <code>mavros/launch/px4_config.yaml</code>. However, the current version of mavros (<code>1.3.0</code>) needs to be able to use the tf tree to find a transform from <code>frame_id</code> to the hardcoded frame <code>odom_ned</code>. The same applies to the <code>child_frame_id</code>, which needs to be connected in the tf tree to the hardcoded frame <code>base_link_frd</code>. If you are using mavros <code>1.2.0</code> and you didn&#39;t update the file <code>mavros/launch/px4_config.yaml</code>, then you can safely use the odometry frames <code>frame_id = odom</code>, <code>child_frame_id = base_link</code> without much worry.</li><li><strong>Note</strong> Remapping pose topics is covered above <a href="#relaying_pose_data_to_px4">Relaying pose data to PX4</a> (<code>/vrpn_client_node/&lt;rigid_body_name&gt;/pose</code> is of type <code>geometry_msgs/PoseStamped</code>).</li></ul><h3 id="参考框架和-ros" tabindex="-1">参考框架和 ROS <a class="header-anchor" href="#参考框架和-ros" aria-label="Permalink to &quot;参考框架和 ROS&quot;">​</a></h3><p>The local/world and world frames used by ROS and PX4 are different.</p><table><thead><tr><th>框架</th><th>ROS</th><th>PX4</th></tr></thead><tbody><tr><td>机体</td><td>FRD (X <strong>F</strong>orward, Y <strong>R</strong>ight, Z <strong>D</strong>own)</td><td>FRD (X <strong>F</strong>orward, Y <strong>R</strong>ight 和 Z <strong>D</strong>own)</td></tr><tr><td>世界坐标系</td><td>ENU (X <strong>E</strong>ast, Y <strong>N</strong>orth and Z Up), with the naming being <code>odom</code> or <code>map</code></td><td>NED (X <strong>N</strong>orth, Y <strong>E</strong>ast, Z <strong>D</strong>own)</td></tr></tbody></table><p>The following steps explain how to feed position estimates from an <a href="http://optitrack.com/systems/#robotics" target="_blank" rel="noreferrer">OptiTrack</a> system to PX4. It is assumed that the MoCap system is calibrated. See <a href="https://www.youtube.com/watch?v=cNZaFEghTBU" target="_blank" rel="noreferrer">this video</a> for a tutorial on the calibration process. 假定 mocap 系统已校准。</p><p>如果你把机体命名为 <code>robot1</code>，你会得到一个主题，比如 <code>/vrpn_client_node/robot1/pose</code></p><p><img src="'+s+`" alt="Reference frames"></p><p>With EKF2 when using external heading estimation, magnetic north can either be ignored and or the heading offset to magnetic north can be calculated and compensated. Depending on your choice the yaw angle is given with respect to either magnetic north or local <em>x</em>.</p><div class="info custom-block"><p class="custom-block-title">When creating the rigid body in the MoCap software, remember to first align the robot&#39;s local <em>x</em> axis with the world <em>x</em> axis otherwise the yaw estimate will have an offset. This can stop the external pose estimate fusion from working properly. Yaw angle should be zero when body and reference frame align.</p></div><p>在设置了上述（特定）系统之一之后，您现在应该可以进行测试了。 After setting up one of the (specific) systems described above you should now be ready to test. The instructions below show how to do so for MoCap and VIO systems If you have an Optitrack system you can use <a href="https://github.com/ros-drivers/mocap_optitrack" target="_blank" rel="noreferrer">mocap_optitrack</a> node which streams the object pose on a ROS topic already in ENU. With a remapping you can directly publish it on <code>mocap_pose_estimate</code> as it is without any transformation and MAVROS will take care of NED conversions.</p><p>The MAVROS odometry plugin makes it easy to handle the coordinate frames. It uses ROS&#39;s tf package. Your external pose system might have a completely different frame convention that does not match the one of PX4. The body frame of the external pose estimate can depend on how you set the body frame in the MOCAP software or on how you mount the VIO sensor on the drone. The MAVROS odometry plugin needs to know how the external pose&#39;s child frame is oriented with respect to either the airframe&#39;s FRD or FLU body frame known by MAVROS. You therefore have to add the external pose&#39;s body frame to the tf tree. This can be done by including an adapted version of the following line into your ROS launch file.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span>  &lt;node pkg=&quot;tf&quot; type=&quot;static_transform_publisher&quot; name=&quot;tf_baseLink_externalPoseChildFrame&quot;</span></span>
<span class="line"><span>        args=&quot;0 0 0 &lt;yaw&gt; &lt;pitch&gt; &lt;roll&gt; base_link &lt;external_pose_child_frame&gt; 1000&quot;/&gt;</span></span></code></pre></div><p>Make sure that you change the values of yaw, pitch and roll such that it properly attaches the external pose&#39;s body frame to the <code>base_link</code> or <code>base_link_frd</code>. Have a look at the <a href="http://wiki.ros.org/tf#static_transform_publisher" target="_blank" rel="noreferrer">tf package</a> for further help on how to specify the transformation between the frames. You can use rviz to check if you attached the frame right. The name of the <code>external_pose_child_frame</code> has to match the child_frame_id of your <code>nav_msgs/Odometry</code> message. The same also applies for the reference frame of the external pose. You have to attach the reference frame of the external pose as child to either the <code>odom</code> or <code>odom_frd</code> frame. Adapt therefore the following code line accordingly.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span>  &lt;node pkg=&quot;tf&quot; type=&quot;static_transform_publisher&quot; name=&quot;tf_odom_externalPoseParentFrame&quot;</span></span>
<span class="line"><span>        args=&quot;0 0 0 &lt;yaw&gt; &lt;pitch&gt; &lt;roll&gt; odom &lt;external_pose_parent_frame&gt; 1000&quot;/&gt;</span></span></code></pre></div><p>Put the robot on the ground and start streaming MoCap feedback. 油门杆推到最低并解锁。 油门杆推到最低并解锁。</p><div class="info custom-block"><p class="custom-block-title">When using the MAVROS <em>odom</em> plugin, it is important that no other node is publishing a transform between the external pose&#39;s reference and child frame. 如果切换成功，飞控会闪绿灯。 绿灯代表：你的外部位置信息已经注入到飞控中，并且位置控制模式已经切换成功。</p><p><a id="setup_specific_systems"></a></p><h2 id="特定的系统设置" tabindex="-1">特定的系统设置 <a class="header-anchor" href="#特定的系统设置" aria-label="Permalink to &quot;特定的系统设置&quot;">​</a></h2><h3 id="光学跟踪-mocap" tabindex="-1">光学跟踪 MoCap <a class="header-anchor" href="#光学跟踪-mocap" aria-label="Permalink to &quot;光学跟踪 MoCap&quot;">​</a></h3><p>油门杆居中，这是油门控制死区。 It is assumed that the MoCap system is calibrated. 同理对于另一个杆。</p><h4 id="设置-motive-mocap-软件" tabindex="-1">设置 <em>Motive</em> mocap 软件 <a class="header-anchor" href="#设置-motive-mocap-软件" aria-label="Permalink to &quot;设置 *Motive* mocap 软件&quot;">​</a></h4><ul><li>将无人机的前进方向与 <a href="https://v20.wiki.optitrack.com/index.php?title=Template:Coordinate_System" target="_blank" rel="noreferrer">system + x-axiss</a> 对齐</li><li><a href="https://www.youtube.com/watch?v=1e6Qqxqe-k0" target="_blank" rel="noreferrer">Define a rigid body in the Motive software</a>。 <a href="https://www.youtube.com/watch?v=1e6Qqxqe-k0" target="_blank" rel="noreferrer">Define a rigid body in the Motive software</a>. Give the robot a name that does not contain spaces, e.g. <code>robot1</code> instead of <code>Rigidbody 1</code></li><li><a href="https://www.youtube.com/watch?v=yYRNG58zPFo" target="_blank" rel="noreferrer">启用帧广播和 VRPN 流</a></li><li>将 &quot;向上&quot; 轴设置为 z 轴（默认值为 y）</li></ul><h4 id="将数据输入-ros-1" tabindex="-1">将数据输入 ROS <a class="header-anchor" href="#将数据输入-ros-1" aria-label="Permalink to &quot;将数据输入 ROS&quot;">​</a></h4><ul><li>安装 <code>vrpn_client_ros</code> 包</li><li>You can get each rigid body pose on an individual topic by running bash roslaunch vrpn_client_ros sample.launch server:=<div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">roslaunch</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> vrpn_client_ros</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> sample.launch</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> server:=</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">mocap</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> machine</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> i</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">p</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span></span></code></pre></div></li></ul><p>If you named the rigidbody as <code>robot1</code>, you will get a topic like <code>/vrpn_client_node/robot1/pose</code></p><h4 id="重新映射-重新映射位置数据" tabindex="-1">重新映射/重新映射位置数据 <a class="header-anchor" href="#重新映射-重新映射位置数据" aria-label="Permalink to &quot;重新映射/重新映射位置数据&quot;">​</a></h4><p>MAVROS provides a plugin to relay pose data published on <code>/mavros/vision_pose/pose</code> to PX4. Assuming that MAVROS is running, you just need to <strong>remap</strong> the pose topic that you get from MoCap <code>/vrpn_client_node/&lt;rigid_body_name&gt;/pose</code> directly to <code>/mavros/vision_pose/pose</code>. Note that there is also a <code>mocap</code> topic that MAVROS provides to feed <code>ATT_POS_MOCAP</code> to PX4, but it is not applicable for EKF2. However, it is applicable with LPE.</p><div class="info custom-block"><p class="custom-block-title">Remapping pose topics is covered above <a href="#relaying_pose_data_to_px4">Relaying pose data to PX4</a> (<code>/vrpn_client_node/&lt;rigid_body_name&gt;/pose</code> is of type <code>geometry_msgs/PoseStamped</code>).</p></div></div><p>Assuming that you have configured EKF2 parameters as described above, PX4 now is set and fusing MoCap data.</p><p>You are now set to proceed to the first flight.</p><h2 id="第一次飞行" tabindex="-1">第一次飞行 <a class="header-anchor" href="#第一次飞行" aria-label="Permalink to &quot;第一次飞行&quot;">​</a></h2><p>After setting up one of the (specific) systems described above you should now be ready to test. The instructions below show how to do so for MoCap and VIO systems</p><h3 id="mocap-first-flight" tabindex="-1">MoCap First Flight <a class="header-anchor" href="#mocap-first-flight" aria-label="Permalink to &quot;MoCap First Flight&quot;">​</a></h3><p>Be sure to perform the following checks before your first flight:</p><ul><li>Set the PX4 parameter <code>MAV_ODOM_LP</code> to 1. PX4 will then stream back the received external pose as MAVLink <a href="https://mavlink.io/en/messages/common.html#ODOMETRY" target="_blank" rel="noreferrer">ODOMETRY</a> messages.</li><li>You can check these MAVLink messages with the <em>QGroundControl</em> <a href="https://docs.qgroundcontrol.com/master/en/qgc-user-guide/analyze_view/mavlink_inspector.html" target="_blank" rel="noreferrer">MAVLink Inspector</a> In order to do this, yaw the vehicle until the quaternion of the <code>ODOMETRY</code> message is very close to a unit quaternion. (w=1, x=y=z=0)</li><li>At this point the body frame is aligned with the reference frame of the external pose system. If you do not manage to get a quaternion close to the unit quaternion without rolling or pitching your vehicle, your frame probably still have a pitch or roll offset. Do not proceed if this is the case and check your coordinate frames again.</li><li>Once aligned you can pick the vehicle up from the ground and you should see the position&#39;s z coordinate decrease. Moving the vehicle in forward direction, should increase the position&#39;s x coordinate. While moving the vehicle to the right should increase the y coordinate. In the case you send also linear velocities from the external pose system, you should also check the linear velocities. Check that the linear velocities are in expressed in the <em>FRD</em> body frame reference frame.</li><li>Set the PX4 parameter <code>MAV_ODOM_LP</code> back to 0. PX4 will stop streaming this message back.</li></ul><p>If those steps are consistent, you can try your first flight.</p><p>Put the robot on the ground and start streaming MoCap feedback. Lower your left (throttle) stick and arm the motors.</p><p>At this point, with the left stick at the lowest position, switch to position control. You should have a green light. The green light tells you that position feedback is available and position control is now activated.</p><p>Put your left stick at the middle, this is the dead zone. With this stick value, the robot maintains its altitude; raising the stick will increase the reference altitude while lowering the value will decrease it. Same for right stick on x and y.</p><p>Increase the value of the left stick and the robot will take off, put it back to the middle right after. Check if it is able to keep its position.</p><p>If it works, you may want to set up an <a href="./offboard_control.html">offboard</a> experiment by sending position-setpoint from a remote ground station.</p>`,74);function T(x,O,P,M,A,S){return r(),a("div",null,[h,e("p",null,[t("For example, if using the Optitrack framework the local frame has "),e("mjx-container",d,[(r(),a("svg",c,p)),f]),t(" and "),e("mjx-container",_,[(r(),a("svg",u,b)),y]),t(" on the horizontal plane ("),v,t(" front and "),k,t(" right) while "),w,t(" axis is vertical and pointing up. A simple trick is swapping axis in order to obtained NED convention.")]),E])}const C=n(l,[["render",T]]);export{R as __pageData,C as default};
