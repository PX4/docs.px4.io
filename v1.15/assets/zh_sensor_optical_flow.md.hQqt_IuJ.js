import{_ as e,a}from"./chunks/px4flow_offset.HQ2vTBh8.js";import{_ as t,c as o,o as r,ab as s}from"./chunks/framework.CUflZczI.js";const w=JSON.parse('{"title":"光流","description":"","frontmatter":{},"headers":[],"relativePath":"zh/sensor/optical_flow.md","filePath":"zh/sensor/optical_flow.md"}'),n={name:"zh/sensor/optical_flow.md"},i=s('<h1 id="光流" tabindex="-1">光流 <a class="header-anchor" href="#光流" aria-label="Permalink to &quot;光流&quot;">​</a></h1><p>_光流传感器_使用下视相机和向下的距离传感器进行速度估计。</p><p>@<a href="https://youtu.be/aPQKgUof3Pc" target="_blank" rel="noreferrer">youtube</a> <em>Video: PX4 holding position using the ARK Flow sensor for velocity estimation (in <a href="./../flight_modes_mc/position.html">Position Mode</a>).</em></p><h2 id="设置" tabindex="-1">设置 <a class="header-anchor" href="#设置" aria-label="Permalink to &quot;设置&quot;">​</a></h2><p>光流的配置需要一个下视摄像头和 <a href="./../sensor/rangefinders.html">距离传感器</a> (最好是激光). 这些设备可以通过MAVLink、I2C或其他总线连接。</p><div class="info custom-block"><p class="custom-block-title">If connected to PX4 via MAVLink the Optical Flow device must publish to the <a href="https://mavlink.io/en/messages/common.html#OPTICAL_FLOW_RAD" target="_blank" rel="noreferrer">OPTICAL_FLOW_RAD</a> topic, and the distance sensor must publish to the <a href="https://mavlink.io/en/messages/common.html#DISTANCE_SENSOR" target="_blank" rel="noreferrer">DISTANCE_SENSOR</a> topic.</p></div><p>在不同方向移动时光流的输出必须如下所示：</p><table><thead><tr><th>Vehicle movement</th><th>Integrated flow</th></tr></thead><tbody><tr><td>Forwards</td><td>+ Y</td></tr><tr><td>Backwards</td><td>- Y</td></tr><tr><td>Right</td><td>- X</td></tr><tr><td>Left</td><td>+ X</td></tr></tbody></table><p>For pure rotations the <code>integrated_xgyro</code> and <code>integrated_x</code> (respectively <code>integrated_ygyro</code> and <code>integrated_y</code>) have to be the same.</p><p>An popular setup is the <a href="./../sensor/px4flow.html">PX4Flow</a> and <a href="./../sensor/lidar_lite.html">Lidar-Lite</a>, as shown below.</p><p><img src="'+e+'" alt="Optical flow lidar attached"></p><p>Sensor data from the optical flow device is fused with other velocity data sources. The approach used for fusing sensor data and any offsets from the center of the vehicle must be configured in the <a href="#estimators">estimator</a>.</p><h2 id="flow-sensors-cameras" tabindex="-1">Flow Sensors/Cameras <a class="header-anchor" href="#flow-sensors-cameras" aria-label="Permalink to &quot;Flow Sensors/Cameras&quot;">​</a></h2><h3 id="ark-flow" tabindex="-1">ARK Flow <a class="header-anchor" href="#ark-flow" aria-label="Permalink to &quot;ARK Flow&quot;">​</a></h3><p><a href="./../dronecan/ark_flow.html">ARK Flow</a> is a <a href="./../dronecan/">DroneCAN</a> optical flow sensor, <a href="./../sensor/rangefinders.html">distance sensor</a>, and IMU. It has a PAW3902 optical flow sensor, Broadcom AFBR-S50LV85D 30 meter distance sensor, and BMI088 IMU.</p><h3 id="pmw3901-based-sensors" tabindex="-1">PMW3901-Based Sensors <a class="header-anchor" href="#pmw3901-based-sensors" aria-label="Permalink to &quot;PMW3901-Based Sensors&quot;">​</a></h3><p><a href="./../sensor/pmw3901.html">PMW3901</a> is an optical flow tracking sensor similar to what you would find in a computer mouse, but adapted to work between 80 mm and infinity. It is used in a number of products, including some from: Bitcraze, Tindie, Hex, Thone and Alientek.</p><h3 id="other-cameras-sensors" tabindex="-1">Other Cameras/Sensors <a class="header-anchor" href="#other-cameras-sensors" aria-label="Permalink to &quot;Other Cameras/Sensors&quot;">​</a></h3><p>It is also possible to use a board/quad that has an integrated camera. For this the <a href="https://github.com/PX4/OpticalFlow" target="_blank" rel="noreferrer">Optical Flow repo</a> can be used (see also <a href="https://github.com/PX4/snap_cam" target="_blank" rel="noreferrer">snap_cam</a>).</p><h2 id="range-finders" tabindex="-1">Range Finders <a class="header-anchor" href="#range-finders" aria-label="Permalink to &quot;Range Finders&quot;">​</a></h2><p>您可以使用任何支持的 <a href="./../sensor/rangefinders.html">距离传感器</a> 然而，我们建议使用激光而不是超声波传感器，因为它的鲁棒性和准确性更高。</p><h2 id="估计器" tabindex="-1">估计器 <a class="header-anchor" href="#估计器" aria-label="Permalink to &quot;估计器&quot;">​</a></h2><p>估计器融合数据从光流传感器和其他资源获得。 The settings for how fusing is done, and relative offsets to vehicle center must be specified for the estimator used.</p><p>The offsets are calculated relative to the vehicle orientation and center as shown below:</p><p><img src="'+a+'" alt="Optical Flow offsets"></p><p>Optical Flow based navigation is enabled by both the availableestimators: EKF2 and LPE (deprecated).</p><p><a id="ekf2"></a></p><h3 id="extended-kalman-filter-ekf2" tabindex="-1">Extended Kalman Filter (EKF2) <a class="header-anchor" href="#extended-kalman-filter-ekf2" aria-label="Permalink to &quot;Extended Kalman Filter (EKF2)&quot;">​</a></h3><p>For optical flow fusion using EKF2, set <a href="./../advanced_config/parameter_reference.html#EKF2_OF_CTRL">EKF2_OF_CTRL</a>.</p><p>If your optical flow sensor is offset from the vehicle centre, you can set this using the following parameters.</p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td><a id="EKF2_OF_POS_X"></a><a href="./../advanced_config/parameter_reference.html#EKF2_OF_POS_X">EKF2_OF_POS_X</a></td><td>X position of optical flow focal point in body frame (default is 0.0m).</td></tr><tr><td><a id="EKF2_OF_POS_Y"></a><a href="./../advanced_config/parameter_reference.html#EKF2_OF_POS_Y">EKF2_OF_POS_Y</a></td><td>Y position of optical flow focal point in body frame (default is 0.0m).</td></tr><tr><td><a id="EKF2_OF_POS_Z"></a><a href="./../advanced_config/parameter_reference.html#EKF2_OF_POS_Z">EKF2_OF_POS_Z</a></td><td>Z position of optical flow focal point in body frame (default is 0.0m).</td></tr></tbody></table>',31),d=[i];function l(h,c,f,p,m,_){return r(),o("div",null,d)}const F=t(n,[["render",l]]);export{w as __pageData,F as default};
