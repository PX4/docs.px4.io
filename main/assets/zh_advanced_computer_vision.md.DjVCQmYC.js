import{_ as i,c as a,a8 as o,o as t}from"./chunks/framework.BDnHobkS.js";const d=JSON.parse('{"title":"计算机视觉 (光流，MoCap， VIO，避障)","description":"","frontmatter":{},"headers":[],"relativePath":"zh/advanced/computer_vision.md","filePath":"zh/advanced/computer_vision.md"}'),n={name:"zh/advanced/computer_vision.md"};function r(l,e,s,p,c,m){return t(),a("div",null,e[0]||(e[0]=[o('<h1 id="计算机视觉-光流-mocap-vio-避障" tabindex="-1">计算机视觉 (光流，MoCap， VIO，避障) <a class="header-anchor" href="#计算机视觉-光流-mocap-vio-避障" aria-label="Permalink to &quot;计算机视觉 (光流，MoCap， VIO，避障)&quot;">​</a></h1><p><a href="https://en.wikipedia.org/wiki/Computer_vision" target="_blank" rel="noreferrer">Computer vision</a> techniques enable computers to use visual data to make sense of their environment.</p><p>PX4 uses computer vision systems (primarily running on <a href="./../companion_computer/">Companion Computers</a>) in order to support the following features:</p><ul><li><a href="#optical-flow">Optical Flow</a> provides 2D velocity estimation (using a downward facing camera and a downward facing distance sensor).</li><li><a href="#motion-capture">Motion Capture</a> provides 3D pose estimation using a vision system that is <em>external</em> to the vehicle. 它主要用于室内导航。</li><li><a href="#visual-inertial-odometry-vio">Visual Inertial Odometry</a> provides 3D pose and velocity estimation using an onboard vision system and IMU. 用于在 GNSS 位置信息不存在或不可靠时的导航。</li><li><a href="./../computer_vision/collision_prevention.html">Collision Prevention</a> is used to stop vehicles before they can crash into an obstacle (primarily when flying in manual modes).</li></ul><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>The <a href="./../complete_vehicles_mc/px4_vision_kit.html">PX4 Vision Autonomy Development Kit</a> (Holybro) is a robust and inexpensive kit for developers working with computer vision on PX4.</p></div><h2 id="运动捕捉" tabindex="-1">运动捕捉 <a class="header-anchor" href="#运动捕捉" aria-label="Permalink to &quot;运动捕捉&quot;">​</a></h2><p>Motion Capture (MoCap) is a technique for estimating the 3D <em>pose</em> (position and orientation) of a vehicle using a positioning mechanism that is <em>external</em> to the vehicle. MoCap 系统最常使用红外相机检测运动，但也可以使用其他类型的相机，激光雷达或者超宽带 （UWB）。</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>MoCap is commonly used to navigate a vehicle in situations where GPS is absent (e.g. indoors), and provides position relative to a <em>local</em> coordinate system.</p></div><p>有关 MoCap 的信息，请参阅：</p><ul><li><a href="./../ros/external_position_estimation.html">External Position Estimation</a></li><li><a href="./../tutorials/motion-capture.html">Flying with Motion Capture (VICON, NOKOV, Optitrack)</a></li><li><a href="./../advanced_config/tuning_the_ecl_ekf.html#external-vision-system">EKF &gt; External Vision System</a></li></ul><h2 id="visual-inertial-odometry-vio" tabindex="-1">Visual Inertial Odometry (VIO) <a class="header-anchor" href="#visual-inertial-odometry-vio" aria-label="Permalink to &quot;Visual Inertial Odometry (VIO)&quot;">​</a></h2><p>Visual Inertial Odometry (VIO) is used for estimating the 3D <em>pose</em> (position and orientation) and <em>velocity</em> of a moving vehicle relative to a <em>local</em> starting position. 它通常用于在 GPS 不存在（例如室内）或不可靠的情况下（例如在桥下飞行时）给载具导航。</p><p>VIO uses <a href="https://en.wikipedia.org/wiki/Visual_odometry" target="_blank" rel="noreferrer">Visual Odometry</a> to estimate vehicle <em>pose</em> from visual information, combined with inertial measurements from an IMU (to correct for errors associated with rapid vehicle movement resulting in poor image capture).</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>One difference between VIO and <a href="#motion-capture">MoCap</a> is that VIO cameras/IMU are vehicle-based, and additionally provide velocity information.</p></div><p>关于在 PX4 上配置 VIO 的信息，请参阅：</p><ul><li><a href="./../advanced_config/tuning_the_ecl_ekf.html#external-vision-system">EKF &gt; External Vision System</a></li><li><a href="./../peripherals/camera_t265_vio.html">T265 Setup guide</a></li></ul><h2 id="光流" tabindex="-1">光流 <a class="header-anchor" href="#光流" aria-label="Permalink to &quot;光流&quot;">​</a></h2><p><a href="./../sensor/optical_flow.html">Optical Flow</a> provides 2D velocity estimation (using a downward facing camera and a downward facing distance sensor).</p><p>有关光流的信息，请参阅：</p><ul><li><a href="./../sensor/optical_flow.html">Optical Flow</a></li><li><a href="./../advanced_config/tuning_the_ecl_ekf.html#optical-flow">EKF &gt; Optical Flow</a></li></ul><h2 id="比较" tabindex="-1">比较 <a class="header-anchor" href="#比较" aria-label="Permalink to &quot;比较&quot;">​</a></h2><h3 id="本地位置估计-光学流-对-vio" tabindex="-1">本地位置估计 光学流 对 VIO <a class="header-anchor" href="#本地位置估计-光学流-对-vio" aria-label="Permalink to &quot;本地位置估计 光学流 对 VIO&quot;">​</a></h3><p>这两种技术都使用照相机并测量帧之间的差异。 光学流使用向下照相机，而VIO则使用立体照相机或45度跟踪照相机。 假定两者的校准都很好，哪个对本地地位置估计更好？</p><p>The consensus <a href="https://discuss.px4.io/t/vio-vs-optical-flow/34680" target="_blank" rel="noreferrer">appears to be</a>:</p><p>Optical flow:</p><ul><li>向下光学流使得你能够通过陀螺仪的角速度来校正角平面速度。</li><li>需要准确的地面距离并假定地面为平面。 在这种情况下，它可能与VIO一样准确可靠(例如室内飞行)</li><li>它比VIO更健壮，因为它的状态较少。</li><li>更便宜和更容易设置，因为它只需要一个流传感器，一个范围探测器。 并设置几个参数（可以连接到飞行控制器）。</li></ul><p>VIO</p><ul><li>购买更加昂贵，设置更加困难。 它需要一台单独的配套计算机、校准、软件、配置等等。</li><li>如果没有可跟踪的点特征（实际上现实世界一般有点特征），效果将会减弱。</li><li>较为灵活，可以增加诸如避免障碍和制图等其他功能。</li></ul><p>组合(两者兼用)可能是最可靠的，但在大多数现实世界的情景中并不必要。 通常您将选择适合您的运行环境、所需功能和成本限制的系统：</p><ul><li>如果您打算在没有GPS的情况下在室外飞行（或室外和室内飞行），请使用 VIO 或者如果您需要支持避障碍和其他计算机视觉特性。</li><li>如果您只计划在室内飞行（不使用 GPS），且成本是一个重要的考虑因素，使用Optical Flow。</li></ul><h2 id="外部资源" tabindex="-1">外部资源 <a class="header-anchor" href="#外部资源" aria-label="Permalink to &quot;外部资源&quot;">​</a></h2><ul><li><a href="https://github.com/robin-shaun/XTDrone/blob/master/README.en.md" target="_blank" rel="noreferrer">XTDrone</a> - ROS + PX4 simulation environment for computer vision. The <a href="https://www.yuque.com/xtdrone/manual_en" target="_blank" rel="noreferrer">XTDrone Manual</a> has everything you need to get started!</li></ul>',32)]))}const u=i(n,[["render",r]]);export{d as __pageData,u as default};
