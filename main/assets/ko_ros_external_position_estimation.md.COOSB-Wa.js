import{_ as s}from"./chunks/ekf2_ev_delay_tuning.DPyJAJWg.js";import{_ as n}from"./chunks/ref_frames.YBU277-S.js";import{_ as l,c as r,a8 as o,j as t,a,o as i}from"./chunks/framework.BDnHobkS.js";const O=JSON.parse('{"title":"위치 추정을 위한 비전 또는 모션 캡처 사용","description":"","frontmatter":{},"headers":[],"relativePath":"ko/ros/external_position_estimation.md","filePath":"ko/ros/external_position_estimation.md"}'),d={name:"ko/ros/external_position_estimation.md"},h={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},m={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.025ex"},xmlns:"http://www.w3.org/2000/svg",width:"1.294ex",height:"1.025ex",role:"img",focusable:"false",viewBox:"0 -442 572 453","aria-hidden":"true"},c={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},p={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.025ex"},xmlns:"http://www.w3.org/2000/svg",width:"1.052ex",height:"1.025ex",role:"img",focusable:"false",viewBox:"0 -442 465 453","aria-hidden":"true"};function f(_,e,g,u,b,k){return i(),r("div",null,[e[13]||(e[13]=o('<h1 id="위치-추정을-위한-비전-또는-모션-캡처-사용" tabindex="-1">위치 추정을 위한 비전 또는 모션 캡처 사용 <a class="header-anchor" href="#위치-추정을-위한-비전-또는-모션-캡처-사용" aria-label="Permalink to &quot;위치 추정을 위한 비전 또는 모션 캡처 사용&quot;">​</a></h1><p>전역 위치 소스를 사용할 수 없거나 신뢰할 수 없는 경우(예: 실내나 다리 아래를 비행시)에, VIO(Visual Inertial Odometry) 및 MoCap(모션 캡처) 시스템을 사용하여 차량 내비게이션이 가능합니다.</p><p>Both VIO and MoCap determine a vehicle&#39;s <em>pose</em> (position and attitude) from &quot;visual&quot; information. 그들 사이의 주요 차이점은 프레임 관점입니다.</p><ul><li>VIO uses <em>onboard sensors</em> to get pose data from the vehicle&#39;s perspective (see <a href="https://en.wikipedia.org/wiki/Visual_odometry#Egomotion" target="_blank" rel="noreferrer">egomotion</a>).</li><li>MoCap uses a system of <em>off-board cameras</em> to get vehicle pose data in a 3D space (i.e. it is an external system that tells the vehicle its pose).</li></ul><p>두 시스템 유형의 포즈 데이터를 사용하여 PX4 자동조종장치의 로컬 위치 추정값(로컬 원점 기준)을 업데이트할 수 있으며, 선택적으로 차량 자세 추정을 융합할 수 있습니다. 또한 외부 포즈 시스템이 선형 속도 측정을 제공하는 경우에는 상태 추정 개선에 사용할 수 있습니다(선속도 측정의 융합은 EKF2에서만 지원됨).</p><p>This topic explains how to configure a PX4-based system to get data from MoCap/VIO systems (either via ROS or some other MAVLink system) and more specifically how to set up MoCap systems like VICON and Optitrack, and vision-based estimation systems like <a href="https://github.com/ethz-asl/rovio" target="_blank" rel="noreferrer">ROVIO</a>, <a href="https://github.com/uzh-rpg/rpg_svo" target="_blank" rel="noreferrer">SVO</a> and <a href="https://github.com/ethz-asl/ethzasl_ptam" target="_blank" rel="noreferrer">PTAM</a>).</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>The instructions differ depending on whether you are using the EKF2 or LPE estimator.</p></div><h2 id="px4-mavlink-통합" tabindex="-1">PX4 MAVLink 통합 <a class="header-anchor" href="#px4-mavlink-통합" aria-label="Permalink to &quot;PX4 MAVLink 통합&quot;">​</a></h2><p>PX4 uses the following MAVLink messages for getting external position information, and maps them to <a href="./../middleware/uorb.html">uORB topics</a>:</p><table tabindex="0"><thead><tr><th>MAVLink</th><th>uORB</th></tr></thead><tbody><tr><td><a href="https://mavlink.io/en/messages/common.html#VISION_POSITION_ESTIMATE" target="_blank" rel="noreferrer">VISION_POSITION_ESTIMATE</a></td><td><code>vehicle_visual_odometry</code></td></tr><tr><td><a href="https://mavlink.io/en/messages/common.html#ODOMETRY" target="_blank" rel="noreferrer">ODOMETRY</a> (<code>frame_id =</code> <a href="https://mavlink.io/en/messages/common.html#MAV_FRAME_LOCAL_FRD" target="_blank" rel="noreferrer">MAV_FRAME_LOCAL_FRD</a>)</td><td><code>vehicle_visual_odometry</code></td></tr><tr><td><a href="https://mavlink.io/en/messages/common.html#ATT_POS_MOCAP" target="_blank" rel="noreferrer">ATT_POS_MOCAP</a></td><td><code>vehicle_mocap_odometry</code></td></tr><tr><td><a href="https://mavlink.io/en/messages/common.html#ODOMETRY" target="_blank" rel="noreferrer">ODOMETRY</a> (<code>frame_id =</code> <a href="https://mavlink.io/en/messages/common.html#MAV_FRAME_MOCAP_NED" target="_blank" rel="noreferrer">MAV_FRAME_MOCAP_NED</a>)</td><td><code>vehicle_mocap_odometry</code></td></tr></tbody></table><p>EKF2 only subscribes to <code>vehicle_visual_odometry</code> topics and can hence only process the first two messages (a MoCap system must generate these messages to work with EKF2). 주행 거리 측정 메시지는 선형 속도도 PX4로 전송 가능한 유일한 메시지입니다. LPE 추정기는 두 주제를 모두 구독하므로, 위의 모든 메시지를 처리할 수 있습니다.</p><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>EKF2 is the default estimator used by PX4. LPE보다 테스트 및 지원이 더 잘 되므로, 우선적으로 사용하여야 합니다.</p></div><p>메시지는 30Hz(공분산을 포함하는 경우)와 50Hz 사이에서 스트리밍되어야 합니다. 메시지 비율이 너무 낮으면, EKF2가 외부 비전 메시지를 융합하지 않습니다.</p><p>The following MAVLink &quot;vision&quot; messages are not currently supported by PX4: <a href="https://mavlink.io/en/messages/common.html#GLOBAL_VISION_POSITION_ESTIMATE" target="_blank" rel="noreferrer">GLOBAL_VISION_POSITION_ESTIMATE</a>, <a href="https://mavlink.io/en/messages/common.html#VISION_SPEED_ESTIMATE" target="_blank" rel="noreferrer">VISION_SPEED_ESTIMATE</a>, <a href="https://mavlink.io/en/messages/common.html#VICON_POSITION_ESTIMATE" target="_blank" rel="noreferrer">VICON_POSITION_ESTIMATE</a></p><h2 id="기준-프레임" tabindex="-1">기준 프레임 <a class="header-anchor" href="#기준-프레임" aria-label="Permalink to &quot;기준 프레임&quot;">​</a></h2><p>PX4 uses FRD (X <strong>F</strong>orward, Y <strong>R</strong>ight and Z <strong>D</strong>own) for the local body frame as well for the reference frame. When using the heading of the magnetometer, the PX4 reference frame x axis will be aligned with north, so therefore it is called NED (X <strong>N</strong>orth, Y <strong>E</strong>ast, Z <strong>D</strong>own). 대부분의 경우 PX4 추정기의 기준 좌표계와 외부 포즈 추정 중 하나가 일치하지 않습니다. Therefore the reference frame of the external pose estimate is named differently, it is called <a href="https://mavlink.io/en/messages/common.html#MAV_FRAME_LOCAL_FRD" target="_blank" rel="noreferrer">MAV_FRAME_LOCAL_FRD</a>.</p><p>기준 프레임의 소스에 따라 MAVLink Vision/MoCap 메시지를 보내기 전에, 포즈 추정값에 사용자 정의 변환을 적용하여야 합니다. 이것은 PX4 규칙에 맞도록 포즈 추정의 상위 및 하위 프레임 방향을 변경하는 데 필요합니다. Have a look at the MAVROS <a href="https://github.com/mavlink/mavros/blob/master/mavros_extras/src/plugins/odom.cpp" target="_blank" rel="noreferrer"><em>odom</em> plugin</a> for the necessary transformations.</p><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>ROS users can find more detailed instructions below in <a href="#reference-frames-and-ros">Reference Frames and ROS</a>.</p></div>',18)),t("p",null,[e[4]||(e[4]=a("For example, if using the Optitrack framework the local frame has ")),t("mjx-container",h,[(i(),r("svg",m,e[0]||(e[0]=[o('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(572,0)"></g></g></g>',1)]))),e[1]||(e[1]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"x"),t("mrow",{"data-mjx-texclass":"ORD"})])],-1))]),e[5]||(e[5]=a(" and ")),t("mjx-container",c,[(i(),r("svg",p,e[2]||(e[2]=[o('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(465,0)"></g></g></g>',1)]))),e[3]||(e[3]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"z"),t("mrow",{"data-mjx-texclass":"ORD"})])],-1))]),e[6]||(e[6]=a(" on the horizontal plane (")),e[7]||(e[7]=t("em",null,"x",-1)),e[8]||(e[8]=a(" front and ")),e[9]||(e[9]=t("em",null,"z",-1)),e[10]||(e[10]=a(" right) while ")),e[11]||(e[11]=t("em",null,"y",-1)),e[12]||(e[12]=a(" axis is vertical and pointing up. 간단한 트릭은 NED 규칙을 얻기 위해 축을 변경하는 것입니다."))]),e[14]||(e[14]=o(`<p>If <code>x_{mav}</code>, <code>y_{mav}</code> and <code>z_{mav}</code> are the coordinates that are sent through MAVLink as position feedback, then we obtain:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>x_{mav} = x_{mocap}</span></span>
<span class="line"><span>y_{mav} = z_{mocap}</span></span>
<span class="line"><span>z_{mav} = - y_{mocap}</span></span></code></pre></div><p>Regarding the orientation, keep the scalar part <em>w</em> of the quaternion the same and swap the vector part <em>x</em>, <em>y</em> and <em>z</em> in the same way. 이 트릭을 모든 시스템에 적용할 수 있습니다. NED 프레임을 가져와야 하는 경우 MoCap 출력을 보고 그에 따라 축을 교체하십시오.</p><h2 id="ekf2-튜닝과-설정" tabindex="-1">EKF2 튜닝과 설정 <a class="header-anchor" href="#ekf2-튜닝과-설정" aria-label="Permalink to &quot;EKF2 튜닝과 설정&quot;">​</a></h2><p>참고: 간략한 개요입니다. For more detailed information, check the <a href="./../advanced_config/tuning_the_ecl_ekf.html">EKF2 tuning guide</a></p><p>The following parameters must be set to use external position information with EKF2 (these can be set in <em>QGroundControl</em> &gt; <strong>Vehicle Setup &gt; Parameters &gt; EKF2</strong>).</p><table tabindex="0"><thead><tr><th>매개변수</th><th>외부 위치 추정 설정</th></tr></thead><tbody><tr><td><a href="./../advanced_config/parameter_reference.html#EKF2_EV_CTRL">EKF2_EV_CTRL</a></td><td>Set <em>horizontal position fusion</em>, <em>vertical vision fusion</em>, <em>velocity fusion</em>, and <em>yaw fusion</em>, according to your desired fusion model.</td></tr><tr><td><a href="./../advanced_config/parameter_reference.html#EKF2_HGT_REF">EKF2_HGT_REF</a></td><td>Set to <em>Vision</em> to use the vision as the reference source for altitude estimation.</td></tr><tr><td><a href="./../advanced_config/parameter_reference.html#EKF2_EV_DELAY">EKF2_EV_DELAY</a></td><td>측정 타임스탬프와 &quot;실제&quot; 캡처 시간 간의 차이로 설정합니다. For more information see <a href="#tuning-EKF2_EV_DELAY">below</a>.</td></tr><tr><td><a href="./../advanced_config/parameter_reference.html#EKF2_EV_POS_X">EKF2_EV_POS_X</a>, <a href="./../advanced_config/parameter_reference.html#EKF2_EV_POS_Y">EKF2_EV_POS_Y</a>, <a href="./../advanced_config/parameter_reference.html#EKF2_EV_POS_Z">EKF2_EV_POS_Z</a></td><td>로봇의 몸체 프레임을 기준으로 비전 센서(또는 MoCap 마커)의 위치를 설정합니다.</td></tr></tbody></table><p>You can also disable GNSS, baro and range finder fusion using <a href="./../advanced_config/parameter_reference.html#EKF2_GPS_CTRL">EKF2_GPS_CTRL</a>, <a href="./../advanced_config/parameter_reference.html#EKF2_BARO_CTRL">EKF2_BARO_CTRL</a> and <a href="./../advanced_config/parameter_reference.html#EKF2_RNG_CTRL">EKF2_RNG_CTRL</a>, respectively.</p><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>Reboot the flight controller in order for parameter changes to take effect.</p></div><p><a id="tuning-EKF2_EV_DELAY"></a></p><h4 id="ekf2-ev-delay-튜닝" tabindex="-1">EKF2_EV_DELAY 튜닝 <a class="header-anchor" href="#ekf2-ev-delay-튜닝" aria-label="Permalink to &quot;EKF2_EV_DELAY 튜닝&quot;">​</a></h4><p><a href="./../advanced_config/parameter_reference.html#EKF2_EV_DELAY">EKF2_EV_DELAY</a> is the <em>Vision Position Estimator delay relative to IMU measurements</em>.</p><p>즉, 비전 시스템 타임스탬프와 IMU 시계(EKF2의 &quot;기본 시계&quot;)에 의해 기록되었을 &quot;실제&quot; 캡처 시간 간의 차이입니다.</p><p>기술적으로, 이것은 MoCap과 (예를 들어) ROS 컴퓨터 사이에 정확한 타임스탬프 (도착 시간이 아님)와 시간 동기화 (예 : NTP)가있는 경우 0으로 설정할 수 있습니다. In reality, this needs some empirical tuning since delays in the entire MoCap-&gt;PX4 chain are very setup-specific. 시스템이 완전히 동기화된 체인으로 설정되는 경우는 매우 드뭅니다.</p><p>IMU 속도와 EV 속도 간의 오프셋을 확인하여, 로그에서 대략적인 지연 추정치를 계산할 수 있습니다. To enable logging of EV rates set bit 7 (Computer Vision and Avoidance) of <a href="./../advanced_config/parameter_reference.html#SDLOG_PROFILE">SDLOG_PROFILE</a>.</p><p><img src="`+s+'" alt="ekf2evdelay log"></p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>A plot of external data vs. onboard estimate (as above) can be generated using <a href="./../log/flight_log_analysis.html#flightplot">FlightPlot</a> or similar flight analysis tools. At time of writing (July 2021) neither <a href="./../log/flight_log_analysis.html#flight-review-online-tool">Flight Review</a> nor <a href="./../log/flight_log_analysis.html#mavgcl">MAVGCL</a> support this functionality.</p></div><p>이 값은 동적 기동 중에 가장 낮은 EKF 혁신을 산출하는 값을 찾기 위하여, 매개변수를 변경하여 추가 튜닝할 수 있습니다.</p><h2 id="lpe-튜닝과-설정" tabindex="-1">LPE 튜닝과 설정 <a class="header-anchor" href="#lpe-튜닝과-설정" aria-label="Permalink to &quot;LPE 튜닝과 설정&quot;">​</a></h2><p>You will first need to <a href="./../advanced/switching_state_estimators.html">switch to the LPE estimator</a> by setting the following parameters: <a href="./../advanced_config/parameter_reference.html#LPE_EN">LPE_EN</a> (1), <a href="./../advanced_config/parameter_reference.html#EKF2_EN">EKF2_EN</a> (0), <a href="./../advanced_config/parameter_reference.html#ATT_EN">ATT_EN</a> (0).</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>If targeting <code>px4_fmu-v2</code> hardware you will also need to use a firmware version that includes the LPE module (firmware for other FMU-series hardware includes both LPE and EKF). The LPE version can be found in the zip file for each PX4 release or it can be built from source using the build command <code>make px4_fmu-v2_lpe</code>. See <a href="./../dev_setup/building_px4.html">Building the Code</a> for more details.</p></div><h3 id="외부-포즈-입력-활성화" tabindex="-1">외부 포즈 입력 활성화 <a class="header-anchor" href="#외부-포즈-입력-활성화" aria-label="Permalink to &quot;외부 포즈 입력 활성화&quot;">​</a></h3><p>The following parameters must be set to use external position information with LPE (these can be set in <em>QGroundControl</em> &gt; <strong>Vehicle Setup &gt; Parameters &gt; Local Position Estimator</strong>).</p><table tabindex="0"><thead><tr><th>매개변수</th><th>외부 위치 추정 설정</th></tr></thead><tbody><tr><td><a href="./../advanced_config/parameter_reference.html#LPE_FUSION">LPE_FUSION</a></td><td>Vision integration is enabled if <em>fuse vision position</em> is checked (it is enabled by default).</td></tr><tr><td><a href="./../advanced_config/parameter_reference.html#ATT_EXT_HDG_M">ATT_EXT_HDG_M</a></td><td>외부 제목 통합을 활성화하려면 1 또는 2로 설정합니다. 1로 설정하면 비전이 사용되는 반면, 2로 설정하면 MoCap 제목 사용이 활성화됩니다.</td></tr></tbody></table><h3 id="기압계-퓨전-비활성화" tabindex="-1">기압계 퓨전 비활성화 <a class="header-anchor" href="#기압계-퓨전-비활성화" aria-label="Permalink to &quot;기압계 퓨전 비활성화&quot;">​</a></h3><p>VIO 또는 MoCap 정보에서 이미 매우 정확한 고도를 사용할 수 있는 경우에는, LPE에서 기압 보정을 비활성화하여 Z축의 드리프트를 줄이는 것이 유용합니다.</p><p>This can be done by in <em>QGroundControl</em> by unchecking the <em>fuse baro</em> option in the <a href="./../advanced_config/parameter_reference.html#LPE_FUSION">LPE_FUSION</a> parameter.</p><h3 id="노이즈-매개변수-조정" tabindex="-1">노이즈 매개변수 조정 <a class="header-anchor" href="#노이즈-매개변수-조정" aria-label="Permalink to &quot;노이즈 매개변수 조정&quot;">​</a></h3><p>If your vision or MoCap data is highly accurate, and you just want the estimator to track it tightly, you should reduce the standard deviation parameters: <a href="./../advanced_config/parameter_reference.html#LPE_VIS_XY">LPE_VIS_XY</a> and <a href="./../advanced_config/parameter_reference.html#LPE_VIS_Z">LPE_VIS_Z</a> (for VIO) or <a href="./../advanced_config/parameter_reference.html#LPE_VIC_P">LPE_VIC_P</a> (for MoCap). 표준변차 매개변수를 줄이면, 추정자가 들어오는 포즈 추정치를 더 신뢰하게 됩니다. 허용된 최소값보다 낮게 설정하고, 강제 저장해야 할 수도 있습니다.</p><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>If performance is still poor, try increasing the <a href="./../advanced_config/parameter_reference.html#LPE_PN_V">LPE_PN_V</a> parameter. 이로 인해 추정자는 속도 추정 중에 측정값을 더 신뢰하게 됩니다.</p></div><h2 id="enabling-auto-modes-with-a-local-position" tabindex="-1">Enabling Auto Modes with a Local Position <a class="header-anchor" href="#enabling-auto-modes-with-a-local-position" aria-label="Permalink to &quot;Enabling Auto Modes with a Local Position&quot;">​</a></h2><p>All PX4 automatic flight modes (such as <a href="./../flight_modes_mc/mission.html">Mission</a>, <a href="./../flight_modes_mc/return.html">Return</a>, <a href="./../flight_modes_mc/land.html">Land</a>, <a href="./../flight_modes_mc/land.html">Hold</a>, <a href="./../flight_modes_mc/orbit.html">Orbit</a>)) require a <em>global</em> position estimate, which would normally come from a GPS/GNSS system.</p><p>Systems that only have a <em>local</em> position estimate (from MOCAP, VIO, or similar) can use the <a href="https://mavlink.io/en/messages/common.html#SET_GPS_GLOBAL_ORIGIN" target="_blank" rel="noreferrer">SET_GPS_GLOBAL_ORIGIN</a> MAVLink message to set the origin of the EKF to a particular global location. EKF will then provide a global position estimate based on origin and local frame position.</p><p>This can then be used when planning and executing indoor missions, or to set a local return point, and so on.</p><h2 id="ros-연동" tabindex="-1">ROS 연동 <a class="header-anchor" href="#ros-연동" aria-label="Permalink to &quot;ROS 연동&quot;">​</a></h2><p>ROS is not <em>required</em> for supplying external pose information, but is highly recommended as it already comes with good integrations with VIO and MoCap systems. PX4는 위와 같이 설정되어 있어야 합니다.</p><h3 id="포즈-데이터를-ros로-가져오기" tabindex="-1">포즈 데이터를 ROS로 가져오기 <a class="header-anchor" href="#포즈-데이터를-ros로-가져오기" aria-label="Permalink to &quot;포즈 데이터를 ROS로 가져오기&quot;">​</a></h3><p>VIO와 MoCap 시스템은 포즈 데이터를 얻는 방법이 다르며, 자체 설정과 주제가 있습니다.</p><p>The setup for specific systems is covered <a href="#setup_specific_systems">below</a>. 다른 시스템의 경우에는 공급업체의 설정 문서를 참고하십시오.</p><p><a id="relaying_pose_data_to_px4"></a></p><h3 id="포즈-데이터를-px4로-중계" tabindex="-1">포즈 데이터를 PX4로 중계 <a class="header-anchor" href="#포즈-데이터를-px4로-중계" aria-label="Permalink to &quot;포즈 데이터를 PX4로 중계&quot;">​</a></h3><p>MAVROS에는 다음 파이프라인을 사용하여 VIO 또는 MoCap 시스템에서 시각적 추정을 릴레이하는 플러그인이 있습니다.</p><table tabindex="0"><thead><tr><th>ROS</th><th>MAVLink</th><th>uORB</th></tr></thead><tbody><tr><td>/mavros/vision_pose/pose</td><td><a href="https://mavlink.io/en/messages/common.html#VISION_POSITION_ESTIMATE" target="_blank" rel="noreferrer">VISION_POSITION_ESTIMATE</a></td><td><code>vehicle_visual_odometry</code></td></tr><tr><td>/mavros/odometry/out (<code>frame_id = odom</code>, <code>child_frame_id = base_link</code>)</td><td><a href="https://mavlink.io/en/messages/common.html#ODOMETRY" target="_blank" rel="noreferrer">ODOMETRY</a> (<code>frame_id =</code> <a href="https://mavlink.io/en/messages/common.html#MAV_FRAME_LOCAL_FRD" target="_blank" rel="noreferrer">MAV_FRAME_LOCAL_FRD</a>)</td><td><code>vehicle_visual_odometry</code></td></tr><tr><td>/mavros/mocap/pose</td><td><a href="https://mavlink.io/en/messages/common.html#ATT_POS_MOCAP" target="_blank" rel="noreferrer">ATT_POS_MOCAP</a></td><td><code>vehicle_mocap_odometry</code></td></tr><tr><td>/mavros/odometry/out (<code>frame_id = odom</code>, <code>child_frame_id = base_link</code>)</td><td><a href="https://mavlink.io/en/messages/common.html#ODOMETRY" target="_blank" rel="noreferrer">ODOMETRY</a> (<code>frame_id =</code> <a href="https://mavlink.io/en/messages/common.html#MAV_FRAME_LOCAL_FRD" target="_blank" rel="noreferrer">MAV_FRAME_LOCAL_FRD</a>)</td><td><code>vehicle_mocap_odometry</code></td></tr></tbody></table><p>위의 파이프라인 중 하나를 LPE와 함께 사용할 수 있습니다.</p><p>EKF2로 작업하는 경우 &quot;비전&quot; 파이프라인만 지원됩니다. To use MoCap data with EKF2 you will have to <a href="http://wiki.ros.org/roslaunch/XML/remap" target="_blank" rel="noreferrer">remap</a> the pose topic that you get from MoCap:</p><ul><li>MoCap ROS topics of type <code>geometry_msgs/PoseStamped</code> or <code>geometry_msgs/PoseWithCovarianceStamped</code> must be remapped to <code>/mavros/vision_pose/pose</code>. The <code>geometry_msgs/PoseStamped</code> topic is most common as MoCap doesn&#39;t usually have associated covariances to the data.</li><li>If you get data through a <code>nav_msgs/Odometry</code> ROS message then you will need to remap it to <code>/mavros/odometry/out</code>, making sure to update the <code>frame_id</code> and <code>child_frame_id</code> accordingly.</li><li>The odometry frames <code>frame_id = odom</code>, <code>child_frame_id = base_link</code> can be changed by updating the file in <code>mavros/launch/px4_config.yaml</code>. However, the current version of mavros (<code>1.3.0</code>) needs to be able to use the tf tree to find a transform from <code>frame_id</code> to the hardcoded frame <code>odom_ned</code>. The same applies to the <code>child_frame_id</code>, which needs to be connected in the tf tree to the hardcoded frame <code>base_link_frd</code>. If you are using mavros <code>1.2.0</code> and you didn&#39;t update the file <code>mavros/launch/px4_config.yaml</code>, then you can safely use the odometry frames <code>frame_id = odom</code>, <code>child_frame_id = base_link</code> without much worry.</li><li>Note that if you are sending odometry data to px4 using <code>child_frame_id = base_link</code>, then you need to make sure that the <code>twist</code> portion of the <code>nav_msgs/Odometry</code> message is <strong>expressed in body frame</strong>, <strong>not in inertial frame!!!!!</strong>.</li></ul><h3 id="기준-프레임과-ros" tabindex="-1">기준 프레임과 ROS <a class="header-anchor" href="#기준-프레임과-ros" aria-label="Permalink to &quot;기준 프레임과 ROS&quot;">​</a></h3><p>ROS와 PX4에서 사용하는 로컬과 전역 프레임은 같지 않습니다.</p><table tabindex="0"><thead><tr><th>프레임</th><th>PX4</th><th>ROS</th></tr></thead><tbody><tr><td>몸체</td><td>FRD (X <strong>F</strong>orward, Y <strong>R</strong>ight, Z <strong>D</strong>own)</td><td>FLU (X <strong>F</strong>orward, Y <strong>L</strong>eft, Z <strong>U</strong>p), usually named <code>base_link</code></td></tr><tr><td>전역</td><td>FRD or NED (X <strong>N</strong>orth, Y <strong>E</strong>ast, Z <strong>D</strong>own)</td><td>FLU or ENU (X <strong>E</strong>ast, Y <strong>N</strong>orth, Z <strong>U</strong>p), with the naming being <code>odom</code> or <code>map</code></td></tr></tbody></table><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>See <a href="http://www.ros.org/reps/rep-0105.html" target="_blank" rel="noreferrer">REP105: Coordinate Frames for Mobile Platforms</a> for more information about ROS frames.</p></div><p>두 프레임 모두 아래 이미지에 표시됩니다(왼쪽의 FRD/오른쪽의 FLU).</p><p><img src="'+n+`" alt="Reference frames"></p><p>외부 방향 추정시 EKF2를 사용하면, 자북을 무시하거나 자북에 대한 방향 오프셋을 계산하고 보상할 수 있습니다. Depending on your choice the yaw angle is given with respect to either magnetic north or local <em>x</em>.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>When creating the rigid body in the MoCap software, remember to first align the robot&#39;s local <em>x</em> axis with the world <em>x</em> axis otherwise the yaw estimate will have an offset. 이렇게 하면 외부 포즈 추정 융합이 제대로 작동하지 않을 수 있습니다. 본체와 기준 좌표계가 정렬될 때 요 각도는 0이어야 합니다.</p></div><p>MAVROS를 사용하면 이 작업이 간단합니다. ROS는 ENU 프레임을 관례로 사용하므로, ENU에서 위치 피드백을 제공하여야 합니다. If you have an Optitrack system you can use <a href="https://github.com/ros-drivers/mocap_optitrack" target="_blank" rel="noreferrer">mocap_optitrack</a> node which streams the object pose on a ROS topic already in ENU. With a remapping you can directly publish it on <code>mocap_pose_estimate</code> as it is without any transformation and MAVROS will take care of NED conversions.</p><p>MAVROS 주행 거리 측정 플러그인을 사용하면, 좌표 프레임을 쉽게 처리할 수 있습니다. ROS의 tf 패키지를 사용합니다. 외부 포즈 시스템에는 PX4와 일치하지 않는 완전히 다른 프레임 규칙이 있을 수 있습니다. 외부 포즈 추정의 바디 프레임은 MOCAP 소프트웨어에서 바디 프레임을 설정하는 방법이나 드론에 VIO 센서를 장착하는 방법에 따라 달라질 수 있습니다. MAVROS 주행 거리 측정 플러그인은 MAVROS에 의해 알려진 기체의 FRD 또는 FLU 본체 프레임과 관련하여 외부 포즈의 자식 프레임이 어떻게 향하고 있는 지 알아야 합니다. 따라서 외부 포즈의 바디 프레임을 tf 트리에 추가하여야 합니다. 이것은 ROS 시작 파일에 다음 줄의 수정된 버전을 포함하여 수행할 수 있습니다.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>  &lt;node pkg=&quot;tf&quot; type=&quot;static_transform_publisher&quot; name=&quot;tf_baseLink_externalPoseChildFrame&quot;</span></span>
<span class="line"><span>        args=&quot;0 0 0 &lt;yaw&gt; &lt;pitch&gt; &lt;roll&gt; base_link &lt;external_pose_child_frame&gt; 1000&quot;/&gt;</span></span></code></pre></div><p>Make sure that you change the values of yaw, pitch and roll such that it properly attaches the external pose&#39;s body frame to the <code>base_link</code> or <code>base_link_frd</code>. Have a look at the <a href="http://wiki.ros.org/tf#static_transform_publisher" target="_blank" rel="noreferrer">tf package</a> for further help on how to specify the transformation between the frames. rviz를 사용하여 프레임을 올바르게 부착했는 지 확인할 수 있습니다. The name of the <code>external_pose_child_frame</code> has to match the child_frame_id of your <code>nav_msgs/Odometry</code> message. 외부 포즈의 기준 프레임에도 동일하게 적용됩니다. You have to attach the reference frame of the external pose as child to either the <code>odom</code> or <code>odom_frd</code> frame. 따라서, 다음 코드 줄을 적절하게 조정하십시오.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>  &lt;node pkg=&quot;tf&quot; type=&quot;static_transform_publisher&quot; name=&quot;tf_odom_externalPoseParentFrame&quot;</span></span>
<span class="line"><span>        args=&quot;0 0 0 &lt;yaw&gt; &lt;pitch&gt; &lt;roll&gt; odom &lt;external_pose_parent_frame&gt; 1000&quot;/&gt;</span></span></code></pre></div><p>If the reference frame has the z axis pointing upwards you can attached it without any rotation (yaw=0, pitch=0, roll=0) to the <code>odom</code> frame. The name of <code>external_pose_parent_frame</code> has to match the frame_id of the odometry message.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>When using the MAVROS <em>odom</em> plugin, it is important that no other node is publishing a transform between the external pose&#39;s reference and child frame. This might break the <em>tf</em> tree.</p></div><p><a id="setup_specific_systems"></a></p><h2 id="특정-시스템-설정" tabindex="-1">특정 시스템 설정 <a class="header-anchor" href="#특정-시스템-설정" aria-label="Permalink to &quot;특정 시스템 설정&quot;">​</a></h2><h3 id="optitrack-mocap" tabindex="-1">OptiTrack MoCap <a class="header-anchor" href="#optitrack-mocap" aria-label="Permalink to &quot;OptiTrack MoCap&quot;">​</a></h3><p>The following steps explain how to feed position estimates from an <a href="https://optitrack.com/motion-capture-robotics/" target="_blank" rel="noreferrer">OptiTrack</a> system to PX4. MoCap 시스템이 보정된 것으로 가정합니다. See <a href="https://www.youtube.com/watch?v=cNZaFEghTBU" target="_blank" rel="noreferrer">this video</a> for a tutorial on the calibration process.</p><h4 id="steps-on-the-motive-mocap-software" tabindex="-1">Steps on the <em>Motive</em> MoCap software <a class="header-anchor" href="#steps-on-the-motive-mocap-software" aria-label="Permalink to &quot;Steps on the _Motive_ MoCap software&quot;">​</a></h4><ul><li>Align your robot&#39;s forward direction with the <a href="https://v20.wiki.optitrack.com/index.php?title=Template:Coordinate_System" target="_blank" rel="noreferrer">system +x-axis</a></li><li><a href="https://www.youtube.com/watch?v=1e6Qqxqe-k0" target="_blank" rel="noreferrer">Define a rigid body in the Motive software</a>. Give the robot a name that does not contain spaces, e.g. <code>robot1</code> instead of <code>Rigidbody 1</code></li><li><a href="https://www.youtube.com/watch?v=yYRNG58zPFo" target="_blank" rel="noreferrer">Enable Frame Broadacst and VRPN streaming</a></li><li>위쪽 축을 Z축으로 설정합니다(기본값은 Y).</li></ul><h4 id="포즈-데이터를-ros로-가져오기-1" tabindex="-1">포즈 데이터를 ROS로 가져오기 <a class="header-anchor" href="#포즈-데이터를-ros로-가져오기-1" aria-label="Permalink to &quot;포즈 데이터를 ROS로 가져오기&quot;">​</a></h4><ul><li>Install the <code>vrpn_client_ros</code> package</li><li>다음 명령어로 개별 주제에 대한 각 강체의 포즈를 얻을 수 있습니다.<div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">roslaunch</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> vrpn_client_ros</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> sample.launch</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> server:=</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">mocap</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> machine</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> i</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">p</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span></span></code></pre></div></li></ul><p>If you named the rigidbody as <code>robot1</code>, you will get a topic like <code>/vrpn_client_node/robot1/pose</code></p><h4 id="포즈-데이터-중계-재매핑" tabindex="-1">포즈 데이터 중계/재매핑 <a class="header-anchor" href="#포즈-데이터-중계-재매핑" aria-label="Permalink to &quot;포즈 데이터 중계/재매핑&quot;">​</a></h4><p>MAVROS provides a plugin to relay pose data published on <code>/mavros/vision_pose/pose</code> to PX4. Assuming that MAVROS is running, you just need to <strong>remap</strong> the pose topic that you get from MoCap <code>/vrpn_client_node/&lt;rigid_body_name&gt;/pose</code> directly to <code>/mavros/vision_pose/pose</code>. Note that there is also a <code>mocap</code> topic that MAVROS provides to feed <code>ATT_POS_MOCAP</code> to PX4, but it is not applicable for EKF2. 그러나 LPE에는 적용됩니다.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>Remapping pose topics is covered above <a href="#relaying_pose_data_to_px4">Relaying pose data to PX4</a> (<code>/vrpn_client_node/&lt;rigid_body_name&gt;/pose</code> is of type <code>geometry_msgs/PoseStamped</code>).</p></div><p>위에서 설명한 대로 EKF2 매개변수를 설정하였으면, 이제 PX4가 설정되고 MoCap 데이터를 통합합니다.</p><p>이제 첫 번째 비행을 진행할 준비가 되었습니다.</p><h2 id="첫-번째-비행" tabindex="-1">첫 번째 비행 <a class="header-anchor" href="#첫-번째-비행" aria-label="Permalink to &quot;첫 번째 비행&quot;">​</a></h2><p>위에서 설명한 (특정) 시스템 중 하나를 설정하였으면, 이제 테스트할 준비가 되었습니다. 아래 지침은 MoCap 및 VIO 시스템에서 수행하는 방법을 설명합니다.</p><h3 id="외부-추정-확인" tabindex="-1">외부 추정 확인 <a class="header-anchor" href="#외부-추정-확인" aria-label="Permalink to &quot;외부 추정 확인&quot;">​</a></h3><p>첫 비행 전에 다음을 확인하십시오.</p><ul><li>Set the PX4 parameter <code>MAV_ODOM_LP</code> to 1. PX4 will then stream back the received external pose as MAVLink <a href="https://mavlink.io/en/messages/common.html#ODOMETRY" target="_blank" rel="noreferrer">ODOMETRY</a> messages.</li><li>You can check these MAVLink messages with the <em>QGroundControl</em> <a href="https://docs.qgroundcontrol.com/master/en/qgc-user-guide/analyze_view/mavlink_inspector.html" target="_blank" rel="noreferrer">MAVLink Inspector</a> In order to do this, yaw the vehicle until the quaternion of the <code>ODOMETRY</code> message is very close to a unit quaternion. (w=1, x=y=z=0)</li><li>이 시점에서 몸체 프레임은 외부 포즈 시스템의 기준 프레임과 정렬됩니다. 차량을 구르거나 피칭하지 않고 단위 쿼터니언에 가까운 쿼터니언을 얻을 수 없다면, 프레임에 여전히 피치 또는 롤 오프셋이 있을 수 있습니다. 이 경우에는 더 이상 진행하지 말고, 좌표 프레임을 다시 확인하십시오.</li><li>정렬되면 지면에서 차량을 들어올릴 수 있으며, 위치의 z 좌표가 감소하는 것을 볼 수 있습니다. 차량을 앞쪽으로 움직이면, 위치의 x 좌표가 증가합니다. 차량을 오른 쪽으로 이동하면, y 좌표는 증가합니다. 외부 포즈 시스템에서 선형 속도도 전송하는 경우에는, 선형 속도를 확인하여야 합니다. Check that the linear velocities are in expressed in the <em>FRD</em> body frame reference frame.</li><li>Set the PX4 parameter <code>MAV_ODOM_LP</code> back to 0. PX4는 이 메시지의 스트리밍을 중지합니다.</li></ul><p>이러한 단계가 유지되면, 첫 번째 비행을 시도할 수 있습니다.</p><p>로봇을 바닥에 놓고, MoCap 피드백 스트리밍을 시작합니다. 왼쪽(스로틀) 스틱을 내리고, 모터를 작동시킵니다.</p><p>이때 왼쪽 스틱을 가장 낮은 위치에 놓고, 위치 제어로 전환합니다. 초록불이 켜져야 합니다. 녹색 표시등은 위치 피드백을 사용할 수 있고, 위치 제어가 활성화되었음을 알려줍니다.</p><p>왼쪽 스틱을 가운데에 놓으면, 데드존입니다. 이 스틱 값으로 로봇은 고도를 유지합니다. 스틱을 올리면 기준 고도가 증가하고, 값을 낮추면 감소합니다. x와 y의 오른쪽 스틱에 대해서도 동일합니다.</p><p>왼쪽 스틱의 값을 높이면 로봇이 이륙합니다. 바로 중간에 다시 놓습니다. 위치를 유지할 수 있는 지 확인하십시오.</p><p>If it works, you may want to set up an <a href="./offboard_control.html">offboard</a> experiment by sending position-setpoint from a remote ground station.</p>`,86))])}const w=l(d,[["render",f]]);export{O as __pageData,w as default};
